# (SASGD) - Stratified Adaptive Stochastic Gradient Descent

### About the Solver

An iterative algorithm that approximates the gradient using finite-differences, sets the step size using backtracking, allows for stratified sampling, and chooses the total sample size based on one-time adaptive rules that update to keep the stochastic and optimality error in a fixed lock-step.

### Properties

**Variable Class:** Continuous.

**Constraints Class:** Unconstrained and variable bounds.

### References
Bollapragada, R., Byrd, R., & Nocedal, J. (2018). Adaptive sampling strategies for stochastic optimization. *SIAM Journal on Optimization*, 28(4), 3312-3343. [Paper](https://epubs.siam.org/doi/abs/10.1137/17M1154679)
