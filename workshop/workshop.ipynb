{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welcome to the coding portion of the SimOpt workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore some warnings that pop up since this is running in a Jupyter notebook\n",
    "# ruff: noqa: E402, F811\n",
    "\n",
    "# Some setup...\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"../\")  # Move one level up to import simopt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"venv\\\\lib\\\\site-packages\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL [0]\n",
    "\n",
    "# Import experiment_base module, which contains functions for experimentation.\n",
    "import simopt.experiment_base as expbase\n",
    "from simopt.experiment_base import PlotType\n",
    "\n",
    "# Import ERM-Example problem and Random Search and ADAM solvers.\n",
    "from simopt.models.ermexample import ERMExampleProblem\n",
    "from simopt.solvers.adam import ADAM\n",
    "from simopt.solvers.randomsearch import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this portion of the workshop, we'll be working with a problem and two solvers.\n",
    "\n",
    "**Problem:** Find the slope ($\\beta_1$) and intercept ($\\beta_0$) coefficients that minimize the training MSE of a simple linear regression model, i.e., least squares regression:\n",
    "\n",
    "$$ \\min_{\\beta_0, \\beta_1} \\frac{1}{n}\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2, $$\n",
    "\n",
    "where $Y(x) = 1 + x + \\epsilon$ and $\\epsilon \\sim N(0, 0.1)$.\n",
    "\n",
    "**Solver:** Random Search\n",
    "* Randomly samples ($\\beta_0$, $\\beta_1$) from a bivariate normal distribution with mean vector (1, 1) and variance-covariance matrix (1, 0; 0, 1).\n",
    "* Draws a fixed number of observations from the training dataset (i.e., a minibatch) and computes the squared error loss.\n",
    "* [Full documentation](https://simopt.readthedocs.io/en/latest/randomsearch.html)\n",
    "\n",
    "**Solver:** ADAM\n",
    "* A gradient-based search. Direct (IPA) gradient estimators are used, if available. Otherwise a finite differences estimator is used.\n",
    "* Takes a fixed number of observations (replications) at each solution. This parameter is called `r`.\n",
    "* [Full documentation](https://simopt.readthedocs.io/en/latest/adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL [1]\n",
    "\n",
    "# Instantiate the problem and the Random Search solver, with specifications.\n",
    "my_problem = ERMExampleProblem(\n",
    "    fixed_factors={\"initial_solution\": (0.0, 0.0), \"budget\": 2000}\n",
    ")\n",
    "my_rand_search_solver = RandomSearch(\n",
    "    fixed_factors={\"crn_across_solns\": True, \"sample_size\": 100}\n",
    ")\n",
    "\n",
    "# Pair the problem and solver for experimentation.\n",
    "myexperiment = expbase.ProblemSolver(problem=my_problem, solver=my_rand_search_solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how Random Search does on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL [2]\n",
    "\n",
    "# Run 10 macroreplications of Random Search on the ERM-Example Problem.\n",
    "myexperiment.run(n_macroreps=10)\n",
    "\n",
    "# Post-process the results.\n",
    "myexperiment.post_replicate(n_postreps=200)\n",
    "expbase.post_normalize(experiments=[myexperiment], n_postreps_init_opt=200)\n",
    "\n",
    "# [Results are saved in a file called experiments/<DATE-TIME>/outputs/RNDSRCH_on_ERM-EXAMPLE-1.pickle.]\n",
    "# [The file is not human-readable, so we'll skip looking at it.]\n",
    "\n",
    "# Plot the (unnormalized) progress curves from the 10 macroreplications.\n",
    "expbase.plot_progress_curves(\n",
    "    experiments=[myexperiment], plot_type=PlotType.ALL, normalize=False\n",
    ")\n",
    "# Plot the (unnormalized) mean progress curve with bootstrapped CIs.\n",
    "expbase.plot_progress_curves(\n",
    "    experiments=[myexperiment], plot_type=PlotType.MEAN, normalize=False\n",
    ")\n",
    "# [The plots should be displayed in the output produced below.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn.\n",
    "\n",
    "### Exercise \\#1\n",
    "\n",
    "In CODE CELL [1], play around with the arguments when initializing `myproblem` and `mysolver`.\n",
    "\n",
    "Vary factors of the ERM-Example problem:\n",
    "- Change the initial solution.\n",
    "- Change the budget, i.e., the max number of replications. \n",
    "\n",
    "Vary factors of the Random Search solver:\n",
    "- Change whether it uses CRN across solutions.\n",
    "- Change the number of replications it takes at each solution.\n",
    "\n",
    "Rerun CODE CELLS [1] and [2]. *What do you observe?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's work with the source code.\n",
    "\n",
    "### Exercise \\#2\n",
    "\n",
    "1. Open the file simopt/model/ermexample.py in the VS Code editor.\n",
    "2. Let's change how random search randomly samples solutions in $\\mathbb{R}^2$. For starters, uncomment Line 193\n",
    "\n",
    "    `beta = tuple([rand_sol_rng.uniform(-2, 2) for _ in range(self.dim)])`\n",
    "\n",
    "    and comment out Lines 194-200\n",
    "    \n",
    "    `beta = tuple(rand_sol_rng.mvnormalvariate(mean_vec=[1.0] * self.dim, cov=np.eye(self.dim), factorized=False))`\n",
    "\n",
    "3. Restart the kernel using the Restart Button at the top of this notebook. This will ensure the new version of the source code is being imported.\n",
    "4. Run COMBO CODE CELL [0 + 1 + 2] below (this effectively reruns CODE CELLS [0], [1], and [2]). *How have the plots changed?*\n",
    "\n",
    "**Extra for Experts:** Come up with your own sampling distribution. Documentation on the types of distributions available can be found [here](https://mrg32k3a.readthedocs.io/en/latest/mrg32k3a.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBO CODE CELL [0 + 1 + 2]\n",
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"venv\\\\lib\\\\site-packages\")\n",
    "sys.path.append(\"..\")\n",
    "import simopt.experiment_base as expbase\n",
    "from simopt.experiment_base import PlotType\n",
    "from simopt.models.ermexample import ERMExampleProblem\n",
    "from simopt.solvers.adam import ADAM\n",
    "from simopt.solvers.randomsearch import RandomSearch\n",
    "\n",
    "my_problem = ERMExampleProblem(\n",
    "    fixed_factors={\"initial_solution\": (0.0, 0.0), \"budget\": 2000}\n",
    ")\n",
    "my_rand_search_solver = RandomSearch(\n",
    "    fixed_factors={\"crn_across_solns\": True, \"sample_size\": 100}\n",
    ")\n",
    "myexperiment = expbase.ProblemSolver(problem=my_problem, solver=my_rand_search_solver)\n",
    "\n",
    "myexperiment.run(n_macroreps=10)\n",
    "myexperiment.post_replicate(n_postreps=200)\n",
    "expbase.post_normalize(experiments=[myexperiment], n_postreps_init_opt=200)\n",
    "myexperiment.log_experiment_results()\n",
    "expbase.plot_progress_curves(\n",
    "    experiments=[myexperiment], plot_type=PlotType.ALL, normalize=False\n",
    ")\n",
    "expbase.plot_progress_curves(\n",
    "    experiments=[myexperiment], plot_type=PlotType.MEAN, normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's bring the ADAM solver into the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL [3]\n",
    "\n",
    "my_adam_solver = ADAM(fixed_factors={\"crn_across_solns\": True, \"r\": 100})\n",
    "# Create a grouping of ERM-Example-RandomSearch and ERM-Example-ADAM pairs.\n",
    "mygroupexperiment = expbase.ProblemsSolvers(\n",
    "    problems=[my_problem], solvers=[my_rand_search_solver, my_adam_solver]\n",
    ")\n",
    "\n",
    "# Run 10 macroreplications of each pair and post-process.\n",
    "mygroupexperiment.run(n_macroreps=10)\n",
    "mygroupexperiment.post_replicate(n_postreps=200)\n",
    "mygroupexperiment.post_normalize(n_postreps_init_opt=200)\n",
    "\n",
    "# Record a summary of the results in a human-readable way.\n",
    "mygroupexperiment.log_group_experiment_results()\n",
    "# [Go check out the file called\n",
    "# experiments/<DATE-TIME>/logs/group_RNDSRCH_ADAM_on_ERM-EXAMPLE-1_group_experiment_results.txt]\n",
    "\n",
    "# Plot the mean progress curve for each solver from the 10 macroreplications.\n",
    "expbase.plot_progress_curves(\n",
    "    experiments=[\n",
    "        mygroupexperiment.experiments[0][0],\n",
    "        mygroupexperiment.experiments[1][0],\n",
    "    ],\n",
    "    plot_type=PlotType.MEAN,\n",
    "    normalize=False,\n",
    ")\n",
    "# [The plot should be displayed in the output produced below.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
